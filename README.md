# HDMapDataset

VLM usually works with a single image. However, autonomous driving dataset images contain multi-view images that describe a scene. VLM with multi-image captioning is necessary to describe overall information in a caption. Therefore, this project aims to modify the existing VLM for multi-image captioning.

This project is not the end goal but a means for the Language Informanistic HD Map Generation project.

## Working VLM Projects
<ul>
<li>GPT-4o-mini</li>
<li>Instruct-Blip</li>
<li>Blip2</li>
<li>LLaVA</li>
<li>MiniGpt-4</li>
</ul>
